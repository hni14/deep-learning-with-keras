# パーセプトロンで論理回路を作成する

## 概要
人間の脳は神経細胞(ニューロン)のネットワークで構成されています。  
この最小単位の神経細胞(ニューロン)を模倣したモデル(アルゴリズム)がパーセプトロンとなります。  
パーセプトロンは、ニューラルネットワーク(ディープラーニング)の起源となるアルゴリズムです。  
このパーセプトロンを発展させていったものが、ニューラルネットワーク(ディープラーニング)になります。  
パーセプトロンを用いて、演算処理を実装する例題を通じて、パーセプトロンの仕組みとニューラルネットワークとの関係を学びます。  

この例題を通じて、以下の理解を目指します。

- パーセプトロンは入力と出力を備える関数である。
- パーセプトロンは関数内に重みとバイアスをパラメータとして持つ。
- パーセプトロンでは、重みとバイアスは人が決める必要がある。
- パーセプトロンを多層化することで、単一のパーセプトロンでは解けない問題を解ける。
- パーセプトロンはニューラルネットワークの一種である。

## パーセプトロン
パーセプトロンとは、複数の入力を受け取り、1つの出力を出すアルゴリズムであり、そのアルゴリズムは関数として実装することができます。  
数式で表現すると以下のようになります。  

<img src="https://latex.codecogs.com/gif.latex?y&space;=&space;h(\sum_{i=0}^{n}w_i*x_i+b)"/>

わかりにくいので、下記に、２つの入力を持つパーセプトロンを図と擬似コードで表現してみます。  

![単純パーセプトロン](img/perceptron.dot.png)

```python
def perceptron(x1, x2):
    def step(x): # ステップ関数
        return 1 if x>0 else 0
    activation = step # 活性化関数

    ### 内部パラメータ
    w1 # x1に対する重み
    w2 # x2に対する重み
    bias # バイアス

    ### 演算処理
    weighted_sum = w1*x1 + w2*x2 # 加重和の計算
    return activation(weighted_sum + bias)
```

パーセプトロンでは、入力に対する重みを内部で保持しており、各入力に重みを掛けて合計した加重和を計算します。  
その加重和に内部で保持しているバイアスを足した値を、出力を生み出す関数に入力し、出力を得ます。  
このような出力を生み出す関数を活性化関数(パーセプトロンにおいてはステップ関数)と呼びます。  
ステップ関数は、入力が0より大き場合は1を出力し、0以下は0と出力する関数です。  
階段のステップのように見えます。  

##### ステップ関数
![ステップ関数](img/step_function.png)

内部パラメータである、重みとバイアスを調整することで、演算処理を実現することができます。  
パーセプトロンを用いた論理演算の実装を見ていきましょう。  

## パーセプトロンによる論理演算ゲート
論理演算ゲートとは、AND, NAND, OR, XORなどの論理演算を実現する関数です。  
どれも２つの入力を受け取り、出力は真か偽のどちらかです。  
これをパーセプトロンで実現するために、重み、バイアス、活性化関数を調整することになります。  
活性化関数について言えば、真か偽のどちらかを出力する関数を活性化関数として用いる必要があります。  
また、パーセプトロンでは、加重和を計算するため、入力を実数とする必要があるため、ここでは、真を1と偽を0と表現します。  

### 単純パーセプトロンによるANDゲート
パーセプトロンによるANDゲートの実装を見てみます。  
ANDゲートとは、下記の入力、出力仕様を実現する関数です。  

##### AND 真理値表
| x1 | x2 | y |
|----|----|---|
| 0  | 0  | 0 |
| 1  | 0  | 0 |
| 0  | 1  | 0 |
| 1  | 1  | 1 |

ANDゲートは、２つの入力を受け付けます。  
また、ANDゲートの出力は0か1のどちらかです。  

先ほどみたパーセプトロンのアルゴリズムの内部パラメータである、重みとバイアス、活性化関数を下記にすることでANDゲートを実現できます。

```
x1に対する重み： 0.5
x2に対する重み： 0.5
バイアス： -0.7
活性化関数：ステップ関数
```

##### ANDゲートの図とpython実装
![ANDゲート](img/and_gate.dot.png)

```python
def AND(x1, x2):
    def step(x): # ステップ関数
        return 1 if x>0 else 0
    activation = step # 活性化関数にステップ関数を使う

    ### 内部パラメータ
    w1 = 0.5 # x1に対する重み
    w2 = 0.5 # x2に対する重み
    bias = -0.7 # バイアス

    ### 演算処理
    weighted_sum = w1*x1 + w2*x2 # 加重和の計算
    return activation(weighted_sum + bias)
```

### 単純パーセプトロンによるNANDゲート
パーセプトロンによるNANDゲートの実装を見てみます。  
NANDゲートとは、下記の入力、出力仕様を実現する関数です。  

##### NAND 真理値表
| x1 | x2 | y |
|----|----|---|
| 0  | 0  | 0 |
| 1  | 0  | 0 |
| 0  | 1  | 0 |
| 1  | 1  | 1 |

NANDゲートは、２つの入力を受け付けます。  
また、NANDゲートの出力は0か1のどちらかです。  

先ほどみたパーセプトロンのアルゴリズムの内部パラメータである、重みとバイアス、活性化関数を下記にすることでNANDゲートを実現できます。

```
x1に対する重み： -0.5
x2に対する重み： -0.5
バイアス： 0.7
活性化関数：ステップ関数
```

##### NANDゲートの図とpython実装

![NANDゲート](img/nand_gate.dot.png)

```python
def NAND(x1, x2):
    def step(x): # ステップ関数
        return 1 if x>0 else 0
    activation = step # 活性化関数にステップ関数を使う

    ### 内部パラメータ
    w1 = -0.5 # x1に対する重み
    w2 = -0.5 # x2に対する重み
    bias = 0.7 # バイアス

    ### 演算処理
    weighted_sum = w1*x1 + w2*x2 # 加重和の計算
    return activation(weighted_sum + bias)
```

### 単純パーセプトロンによるORゲート
パーセプトロンによるORゲートの実装を見てみます。  
ORゲートとは、下記の入力、出力仕様を実現する関数です。  

##### OR 真理値表
| x1 | x2 | y |
|----|----|---|
| 0  | 0  | 0 |
| 1  | 0  | 0 |
| 0  | 1  | 0 |
| 1  | 1  | 1 |

ORゲートは、２つの入力を受け付けます。  
また、ORゲートの出力は0か1のどちらかです。  

先ほどみたパーセプトロンのアルゴリズムの内部パラメータである、重みとバイアス、活性化関数を下記にすることでORゲートを実現できます。

```
x1に対する重み： 0.5
x2に対する重み： 0.5
バイアス： -0.2
活性化関数：ステップ関数
```

##### ORゲートの図とpython実装
![ORゲート](img/or_gate.dot.png)

```python
def OR(x1, x2):
    def step(x): # ステップ関数
        return 1 if x>0 else 0
    activation = step # 活性化関数にステップ関数を使う

    ### 内部パラメータ
    w1 = 0.5 # x1に対する重み
    w2 = 0.5 # x2に対する重み
    bias = -0.2 # バイアス

    ### 演算処理
    weighted_sum = w1*x1 + w2*x2 # 加重和の計算
    return activation(weighted_sum + bias)
```

### 多層パーセプトロンによるXORゲート
パーセプトロンによるXORゲートの実装を見てみます。  
XORゲートとは、下記の入力、出力仕様を実現する関数です。  

##### XOR 真理値表
| x1 | x2 | y |
|----|----|---|
| 0  | 0  | 0 |
| 1  | 0  | 1 |
| 0  | 1  | 1 |
| 1  | 1  | 0 |

XORゲートは、２つの入力を受け付けます。  
また、XORゲートの出力は0か1のどちらかです。  

しかしながら、パーセプトロンでは、XORは実装できません。  
正確に言うと、単一のパーセプトロンだけでは実現できません。  

まずは、ANDゲート、NANDゲート、ORゲートの３次元グラフを見てみましょう。  

##### ANDゲートの３D表現
![ANDゲート3D](img/and_gate.png)

##### NANDゲートの３D表現
![NANDゲート3D](img/nand_gate.png)

##### ORゲートの３D表現
![ORゲート3D](img/or_gate.png)

どの論理ゲートも、「崖」がみられます。  
その「崖」を堺に、yの論理値が変わっています。  
XORゲートでは、x1,x2 = (1, 0,)、x1,x2 = (0, 1)の時に、yが1になり、x1,x2 = (0), 0,)、x1,x2 = (0, 0)の時に、yが0になりますが、そのような「崖」を描けるでしょうか。  

XORゲートは複数のパーセプトロンを組み合わせて表現することができます。  
具体的には、NANDゲート、ORゲート、ANDゲートを実現するパーセプトロンを層にして組み合わせます。  

##### XORゲートの図とpython実装
![XORゲート](img/xor_gate.dot.png)

```python
def XOR(x1, x2):
    return AND(NAND(x1, x2), OR(x1, x2))
```

##### XORゲートの３D表現
![XORゲート3D](img/xor_gate.png)

## Q. ADDゲートとMINUSゲートを実装してください。
足し算、引き算を行う算術演算ゲート

```python
def ADD(x1, x2):
    activation = ? # 活性化関数

    ### 内部パラメータ
    w1 = ? # x1に対する重み
    w2 = ? # x2に対する重み
    bias = ? # バイアス

    ### 演算処理
    weighted_sum = w1*x1 + w2*x2 # 加重和の計算
    return activation(weighted_sum + bias)
```

```python
def MINUS(x1, x2):
    activation = ? # 活性化関数

    ### 内部パラメータ
    w1 = ? # x1に対する重み
    w2 = ? # x2に対する重み
    bias = ? # バイアス

    ### 演算処理
    weighted_sum = w1*x1 + w2*x2 # 加重和の計算
    return activation(weighted_sum + bias)
```

## ニューラルネットワーク
パーセプトロンについて理解を深めました。  
それでは、ニューラルネットワークとパーセプトロンはどのように関係しているでしょうか。  

結論としては、パーセプトロンはニューラルネットワークの一種です。  
パーセプトロンとは、ステップ関数を活性化関数として用いるニューラルネットワークの呼称です。  
逆に言えば、活性化関数にステップ関数を用いているニューラルネットワークが、パーセプトロンと言えます。  

ニューラルネットワークとは、パーセプトロンと同様に入力信号に重みを掛けた加重和にバイアスを加えた値を活性化関数を介して出力します。  
また、ニューラルネットワークはパーセプトロンと同様にN層の構造を持つことができます。  
パーセプトロンの場合は、層の数に応じて、単純パーセプトロン、多層パーセプトロンと呼ばれます。  

|演算|活性化関数|層の数|分類|大分類|
|---|---|---|---|---|
|AND|ステップ関数|1|単純パーセプトロン|ニューラルネットワーク|
|OR|ステップ関数|1|単純パーセプトロン|ニューラルネットワーク|
|NAND|ステップ関数|1|単純パーセプトロン|ニューラルネットワーク|
|XOR|ステップ関数|2|多層パーセプトロン|ニューラルネットワーク|
|ADD|項等関数|1|-|ニューラルネットワーク|
|MINUS|項等関数|1|-|ニューラルネットワーク|

## 参考
- [Perceptron: The Artificial Neuron](https://towardsdatascience.com/perceptron-the-artificial-neuron-4d8c70d5cc8d)